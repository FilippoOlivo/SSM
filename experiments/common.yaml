dataset:
    sequence_len: 64
    batch_size: 64
    vocab_size: 16
    mem_tokens: 16
    selective: False

trainer:
    steps: 400000
    optimizer_class: torch.optim.Adam
    optimizer_params:
        lr: 0.0001
    device: "cuda"

metric_tracker:
    logging_steps: 100
    enable_progress_bar: False
    patience: 100
    repo: "/mnt/disk1/folivo/ssm/"

model:
    n_layers: 2
    dt_min: 0.001
    dt_max: 0.1
    model_dim: 64
    hid_dim: 16
