dataset:
    sequence_len: 50
    batch_size: 64
    vocab_size: 16
    mem_tokens: 16
    selective: False

trainer:
    steps: 4
    optimizer_class: torch.optim.Adam
    optimizer_params:
        lr: 0.0001
    device: "cpu"

metric_tracker:
    logging_steps: 100
    enable_progress_bar: False
    patience: 40
    repo: "logs/"